{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ___Imports___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, r2_score, accuracy_score, recall_score, precision_score, classification_report\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ___Load Data___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'class', 'mass', 'fall', 'year', 'lat', 'long', 'Elevation'], dtype='object')\n",
      "      id        class      mass  fall    year       lat       long   Elevation\n",
      "0    1.0           L5      21.0  Fell  1880.0  50.77500    6.08333  333.548386\n",
      "1    2.0           H6     720.0  Fell  1951.0  56.18333   10.23333  333.548386\n",
      "2    6.0          EH4  107000.0  Fell  1952.0  54.21667 -113.00000  333.548386\n",
      "3   10.0  Acapulcoite    1914.0  Fell  1976.0  16.88333  -99.90000  333.548386\n",
      "4  370.0           L6     780.0  Fell  1902.0 -33.16667  -64.95000  333.548386\n",
      "(88705, 8)\n",
      "\n",
      "--------\n",
      "\n",
      "Converted to Dataframe: \n",
      "\n",
      "            id        class           mass  fall    year        lat  \\\n",
      "0          1.0           L5      21.000000  Fell  1880.0  50.775000   \n",
      "1          2.0           H6     720.000000  Fell  1951.0  56.183330   \n",
      "2          6.0          EH4  107000.000000  Fell  1952.0  54.216670   \n",
      "3         10.0  Acapulcoite    1914.000000  Fell  1976.0  16.883330   \n",
      "4        370.0           L6     780.000000  Fell  1902.0 -33.166670   \n",
      "...        ...          ...            ...   ...     ...        ...   \n",
      "88700  75686.0          NaN   13278.078549   NaN  2005.0 -38.000000   \n",
      "88701  75687.0          NaN   13278.078549   NaN  2005.0 -38.000000   \n",
      "88702  75691.0          NaN   13278.078549   NaN  2005.0 -36.816110   \n",
      "88703  75692.0          NaN   13278.078549   NaN  2005.0 -36.816110   \n",
      "88704  78769.0          NaN   13278.078549   NaN  2005.0  53.033333   \n",
      "\n",
      "             long   Elevation  \n",
      "0        6.083330  333.548386  \n",
      "1       10.233330  333.548386  \n",
      "2     -113.000000  333.548386  \n",
      "3      -99.900000  333.548386  \n",
      "4      -64.950000  333.548386  \n",
      "...           ...         ...  \n",
      "88700  145.000000  100.000000  \n",
      "88701  145.000000  100.000000  \n",
      "88702  144.680991  233.000000  \n",
      "88703  144.680991  233.000000  \n",
      "88704   20.716667  150.000000  \n",
      "\n",
      "[88705 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data = pd.read_csv('../data/ALL_DATA.csv')\n",
    "print(data.columns)\n",
    "\n",
    "\n",
    "print(data.head())\n",
    "print(np.shape(data))\n",
    "\n",
    "print('\\n--------\\n')\n",
    "\n",
    "# Turn into Dataframe\n",
    "print(\"Converted to Dataframe: \\n\")\n",
    "all_data = pd.DataFrame(data=data)\n",
    "print(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ___Scaling (10%)___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Stats: \n",
      "\n",
      "                 id          mass          year           lat          long  \\\n",
      "count  88705.000000  8.870500e+04  88705.000000  88705.000000  88705.000000   \n",
      "mean   37088.348053  1.327808e+04   1999.326928      2.815932     38.871848   \n",
      "std    23580.335315  4.121868e+05     21.440582     50.503054     70.303823   \n",
      "min        1.000000  0.000000e+00    301.000000    -87.366670   -174.833333   \n",
      "25%    16281.000000  3.000000e+01   1998.000000    -38.630000      8.192500   \n",
      "50%    34337.000000  1.200000e+04   2002.000000     23.000000     26.000000   \n",
      "75%    56576.000000  1.327808e+04   2008.000000     45.968889     58.407850   \n",
      "max    80694.000000  6.000000e+07   2501.000000     82.569167    354.473330   \n",
      "\n",
      "          Elevation  \n",
      "count  88705.000000  \n",
      "mean     333.548386  \n",
      "std      375.385323  \n",
      "min      -11.000000  \n",
      "25%      100.000000  \n",
      "50%      333.548386  \n",
      "75%      333.548386  \n",
      "max     9999.000000  \n",
      "\n",
      "--------\n",
      "\n",
      "New Sample Data Stats: \n",
      "\n",
      "                 id          mass         year          lat         long  \\\n",
      "count   8870.000000  8.870000e+03  8870.000000  8870.000000  8870.000000   \n",
      "mean   37021.583766  8.026057e+03  1999.107155     2.557869    39.658546   \n",
      "std    23575.968913  3.562619e+04    26.576604    51.054846    69.942534   \n",
      "min        4.000000  0.000000e+00   301.000000   -86.716670  -165.116670   \n",
      "25%    16487.000000  2.760000e+01  1998.000000   -71.500000     8.649167   \n",
      "50%    33808.500000  9.827500e+03  2002.000000    23.254845    26.000000   \n",
      "75%    56581.750000  1.327808e+04  2008.000000    46.511111    59.683333   \n",
      "max    80674.000000  2.753000e+06  2101.000000    73.883333   178.050000   \n",
      "\n",
      "         Elevation  \n",
      "count  8870.000000  \n",
      "mean    327.935051  \n",
      "std     357.428963  \n",
      "min      -3.000000  \n",
      "25%     100.000000  \n",
      "50%     333.548386  \n",
      "75%     333.548386  \n",
      "max    3865.000000  \n"
     ]
    }
   ],
   "source": [
    "# *****************************\n",
    "# HIGHLY IMPORTANT\n",
    "# *****************************\n",
    "\n",
    "# Sample data\n",
    "print(\"Original Data Stats: \\n\")\n",
    "print(all_data.describe())\n",
    "\n",
    "print('\\n--------\\n')\n",
    "\n",
    "print(\"New Sample Data Stats: \\n\")\n",
    "all_data = all_data.sample(frac=0.1)  # 10% sample set\n",
    "print(all_data.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ___Target and Feature Variables___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'class', 'mass', 'fall', 'lat', 'long', 'Elevation'], dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# target variable\n",
    "target = data.year\n",
    "# features\n",
    "features = data.drop(['year'], axis=1)\n",
    "\n",
    "\n",
    "# print(data.head())\n",
    "features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ___Encoding (One-Hot)___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "0        0.0\n",
      "1        0.0\n",
      "2        0.0\n",
      "3        1.0\n",
      "4        0.0\n",
      "        ... \n",
      "88700    0.0\n",
      "88701    0.0\n",
      "88702    0.0\n",
      "88703    0.0\n",
      "88704    0.0\n",
      "Name: class, Length: 88705, dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "0        1.0\n",
      "1        1.0\n",
      "2        1.0\n",
      "3        1.0\n",
      "4        1.0\n",
      "        ... \n",
      "88700    0.0\n",
      "88701    0.0\n",
      "88702    0.0\n",
      "88703    0.0\n",
      "88704    0.0\n",
      "Name: fall, Length: 88705, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# ### Categorical data to be converted to numeric data\n",
    "# class_data = list(all_data['class'])\n",
    "# fall_data = list(all_data['fall'])\n",
    "\n",
    "class_data = list(features['class'])\n",
    "fall_data = list(features['fall'])\n",
    "\n",
    "### integer mapping using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "class_encoded = le.fit_transform(class_data)\n",
    "fall_encoded = le.fit_transform(fall_data)\n",
    "class_encoded = class_encoded.reshape(len(class_encoded), 1)\n",
    "fall_encoded = fall_encoded.reshape(len(fall_encoded), 1)\n",
    "\n",
    "### One hot encoding\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "onehot_encoded_class = onehot_encoder.fit_transform(class_encoded)\n",
    "onehot_encoded_fall = onehot_encoder.fit_transform(fall_encoded)\n",
    "\n",
    "# print(onehot_encoded_class)\n",
    "# all_data['class'] = onehot_encoded_class\n",
    "# print(all_data['class'])\n",
    "\n",
    "# print('\\n\\n\\n')\n",
    "# print(onehot_encoded_fall)\n",
    "# all_data['fall'] = onehot_encoded_fall\n",
    "# print(all_data['fall'])\n",
    "\n",
    "print(onehot_encoded_class)\n",
    "features['class'] = onehot_encoded_class\n",
    "print(features['class'])\n",
    "\n",
    "print('\\n\\n\\n')\n",
    "print(onehot_encoded_fall)\n",
    "features['fall'] = onehot_encoded_fall\n",
    "print(features['fall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ___Build Model___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_model(data, target):  #x,y\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.25, random_state=0)\n",
    "    pipeline = make_pipeline(LogisticRegression())\n",
    "    model = pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    return (X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value distribution of features: \n",
      "[1.0, 0.0, 21.0, 1.0, 50.775, 6.08333, 333.54838634618517]\n",
      "\n",
      "\n",
      "Value distribution after min max: \n",
      "[0.0, 0.0, 3.5e-07, 1.0, 0.8129048746259518, 0.3417993308340014, 0.03442041821640212]\n",
      "\n",
      "\n",
      "Value distribution after std: \n",
      "[-1.5728172058230052, -0.024680562891811992, -0.032162975554411624, 8.895559827418387, 0.9496324358654531, -0.466385781116156, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# print(\"Value distribution of features: \")\n",
    "# print(list(all_data.iloc[0]))\n",
    "\n",
    "# min_max = MinMaxScaler()\n",
    "# data_min_max = min_max.fit_transform(all_data)\n",
    "# print('\\n')\n",
    "# print(\"Value distribution after min max: \")\n",
    "# print(list(data_min_max[0]))\n",
    "\n",
    "# std = StandardScaler()\n",
    "# data_std = std.fit_transform(all_data)\n",
    "# print('\\n')\n",
    "# print(\"Value distribution after std: \")\n",
    "# print(list(data_std[0]))\n",
    "\n",
    "print(\"Value distribution of features: \")\n",
    "print(list(features.iloc[0]))\n",
    "\n",
    "min_max = MinMaxScaler()\n",
    "data_min_max = min_max.fit_transform(features)\n",
    "print('\\n')\n",
    "print(\"Value distribution after min max: \")\n",
    "print(list(data_min_max[0]))\n",
    "\n",
    "std = StandardScaler()\n",
    "data_std = std.fit_transform(features)\n",
    "print('\\n')\n",
    "print(\"Value distribution after std: \")\n",
    "print(list(data_std[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ___Model Evaluation___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id  class           mass  fall        lat        long   Elevation\n",
      "0          1.0    0.0      21.000000   1.0  50.775000    6.083330  333.548386\n",
      "1          2.0    0.0     720.000000   1.0  56.183330   10.233330  333.548386\n",
      "2          6.0    0.0  107000.000000   1.0  54.216670 -113.000000  333.548386\n",
      "3         10.0    1.0    1914.000000   1.0  16.883330  -99.900000  333.548386\n",
      "4        370.0    0.0     780.000000   1.0 -33.166670  -64.950000  333.548386\n",
      "...        ...    ...            ...   ...        ...         ...         ...\n",
      "88700  75686.0    0.0   13278.078549   0.0 -38.000000  145.000000  100.000000\n",
      "88701  75687.0    0.0   13278.078549   0.0 -38.000000  145.000000  100.000000\n",
      "88702  75691.0    0.0   13278.078549   0.0 -36.816110  144.680991  233.000000\n",
      "88703  75692.0    0.0   13278.078549   0.0 -36.816110  144.680991  233.000000\n",
      "88704  78769.0    0.0   13278.078549   0.0  53.033333   20.716667  150.000000\n",
      "\n",
      "[88705 rows x 7 columns]\n",
      "0        1880.0\n",
      "1        1951.0\n",
      "2        1952.0\n",
      "3        1976.0\n",
      "4        1902.0\n",
      "          ...  \n",
      "88700    2005.0\n",
      "88701    2005.0\n",
      "88702    2005.0\n",
      "88703    2005.0\n",
      "88704    2005.0\n",
      "Name: year, Length: 88705, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Data Variable\n",
    "# x = all_data[all_data.columns[0]]\n",
    "x = features\n",
    "print(x)\n",
    "#Target Variable\n",
    "# y = all_data[all_data.columns[1]]\n",
    "y = target\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMax:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-1d22f10f8f03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MinMax:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_min_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MSE: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-b92d6064f633>\u001b[0m in \u001b[0;36mdata_model\u001b[0;34m(data, target)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    354\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1531\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[1;32m   1532\u001b[0m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0;32m-> 1533\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1534\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    167\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    168\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "# print(\"Base:\")\n",
    "# X_test, y_test, model = data_model(x, y)\n",
    "# prediction = model.predict(X_test)\n",
    "# print(\"MSE: {}\".format(mean_squared_error(y_test, prediction)))\n",
    "# print(\"R Squared: {}\".format(r2_score(y_test, prediction)))\n",
    "# print('\\n')\n",
    "\n",
    "\n",
    "print(\"MinMax:\")\n",
    "X_test, y_test, model = data_model(data_min_max, y)\n",
    "prediction = model.predict(X_test)\n",
    "print(\"MSE: {}\".format(mean_squared_error(y_test, prediction)))\n",
    "print(\"R Squared: {}\".format(r2_score(y_test, prediction)))\n",
    "print(\"Confusion Matrix: {}\".format(confusion_matrix(y_test, prediction.round())))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, prediction.round(), normalize=False)))\n",
    "print(\"Recall Score: {}\".format(recall_score(y_test, prediction.round(), average=None)))\n",
    "print(\"Precision Score: {}\".format(precision_score(y_test, prediction.round(), average=None)))\n",
    "print(\"Classification Report: {}\".format(classification_report(y_test, prediction.round())))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "\n",
    "print(\"Std:\")\n",
    "X_test, y_test, model = data_model(data_std, y)\n",
    "prediction = model.predict(X_test)\n",
    "print(\"MSE: {}\".format(mean_squared_error(y_test, prediction)))\n",
    "print(\"R Squared: {}\".format(r2_score(y_test, prediction)))\n",
    "print(\"Confusion Matrix: {}\".format(confusion_matrix(y_test, prediction.round())))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, prediction.round(), normalize=False)))\n",
    "print(\"Recall Score: {}\".format(recall_score(y_test, prediction.round(), average=None)))\n",
    "print(\"Precision Score: {}\".format(precision_score(y_test, prediction.round(), average=None)))\n",
    "print(\"Classification Report: {}\".format(classification_report(y_test, prediction.round())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ___Stop here as this model is meant for classification not regression___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
